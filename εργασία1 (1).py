# -*- coding: utf-8 -*-
"""Εργασία1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fc4qYdsLxeF78P7is7Q2SD1WD6O8emHN

# Εισαγωγή των βιβλιοθηκών
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression

"""## Φόρτωση των δεδομένων:






"""

from google.colab import files
uploded=files.upload()

df = pd.read_csv('diabetes.csv')

"""# Περιγραφή κάθε χαρακτηριστικού:




"""

df.describe()

"""# Δημιουργία Ιστογραμμάτων

"""

df.hist(figsize=(12,10), bins=20, edgecolor='black')
plt.show()

"""**Ραβδόγραμμα για το Outcome**"""

sns.countplot(x='Outcome', data=df, edgecolor='black')
plt.show()

"""# ***Εξήγηση Ποιότητας Δεδομένων***

Με βάση τα ιστογράμματα καταλαβαίνουμε οτι υπάρχει πρόβλημα ποιότητας των δεδομένων. Συγκεκριμένα, παρατηρούνται μηδενικές τιμές για κάποια χαρακτηριστικά οι οποίες δεν βγάζουν νόημα και είναι παράλογες πχ η γλυκόζη, η αρτητιακή πίεση, η πυκνότητα δέρματος, BMI, και η ινσουλίνη.  

Επιπλέον, μπορούμε να θέσουμε το κρητήριο της ομοιομορφίας στην κατανομή των δεδομένων. Παρατηρούμε οτι τα επίπεδα του BMI συγκεντρώνονται σε ένα συγκεκριμένο εύρος και δεν υπάρχει μεγάλη διακύμανση, όπως και στην ινσουλίνη, έχουμε μεγάλη συγκέντρωση σητν αρχή του ιστογράμματος.

Τέλος, βλέπουμε ότι στο ιστόγραμμα του otcome υπάρχει έντονη ανισορροπία στα δεδομένα, κάτι που θα κάνει την εκπάιδευση λανθασμένη.

# **Κατανομή μεταβλητής Age**
Γενικά χαρακτηριστικά:
"""

df['Age'].describe()

"""## Δημιουργία γραφήματος για την ηλικία:"""

plt.hist(df['Age'], bins=20, edgecolor='black')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title("Age")
plt.show()

"""Βλέποντας την κανανομή των ηλικιών πό το ιστόγραμμα καταλαβαίνουμε οτι η κατανομή είναι πολύ ασσύμετρη. Υπάρχουν περισσότεροι νέοι στο dataset παρά ηλιικιωμένοι, κάτι που θα εκπαιδεύσει το μοντέλο σε αυτές τις ηλικίες και δεν θα προβλέπει σωστά για μεγαλύτερες ηλικίες, οι οποίες είνι και πιο πιθανό να εμφανίσουν διαβήτη. *κείμενο σε πλάγια γραφή*

# Οπτικοποίηση της σχέσης της Γλυκόζης και του Outcome

Για να μπορέσουμε να συγκρίνουμε αν τα αυξημένα επίπεδα γλυκόζης οδηγούν σε διαβήτη, δηλαδή σε outcome 1, θα τα εμφανίσουμε σε ένα κοινό διάγραμμα:
"""

sns.boxplot(x='Outcome', y='Glucose', data=df)
plt.title('Συσχέτιση Γλυκόζης και Διαβήτη στους ασθενείς')
plt.show()

"""Είναι εμφανές από το γράφημα ότι οι ασθενείς με διαβήτη (Outcome=1) εχουν υψηλότερες τιμές γλυκόζης στο αίμα σε αντίθεση με τους ασθενείς χωρίς διαβήτη.

# Δημιουργία Numpy Arrays:
"""

X=df.drop('Outcome', axis=1).values
y=df['Outcome'].values

"""# Διαχωρισμός των Δεδομένων:"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)

"""## Εμφάνιση πλήθος παραδειγμάτων:"""

print("Πλήος δειγμάτων εκπαίδευσης:", X_train.shape[0])
print("Πλήθος δειγμάτων επικύρωσης:", X_test.shape[0])

"""## Δημιουργία Μοντέλου:"""

model=LogisticRegression(random_state=0, max_iter=1000)
model.fit(X_train, y_train)

"""# Ακρίβεια των δεδομένων train και test:"""

y_train_pred=model.predict(X_train)
train_accuracy= accuracy_score(y_train, y_train_pred)

y_test_pred=model.predict(X_test)
test_accuracy=accuracy_score(y_test, y_test_pred)

print("Η ακρίβεια για το training set:", train_accuracy)
print("Η ακρίβεια για το test set:", test_accuracy)

"""Παρατηρώ ότι η ακρίβεια για το test set είναι ελαφρώς μεγαλύτερη από το training set. Άρα το μοντέλο φαίνεται να κάνει καλή γενίκευση.
Παρ' όλα αυτά,  θεωρώ ότι η ακρίβεια του μοντέλου γενικά είναι μέτρια. Σαφώς και στις περιπτώσεις που ο ασθενής έχει διαβήτη και δεν δείξει το μοντέλο ότι έχει, είναι πολύ πιο σοβαρές, σε σχέση με το αν ο ασθενής δεν έχει και το μοντέλο προβλέψει το αντίθετο. Ιδανικότερα θα έλαμε να έχουμε παραπάνω ακρίβεια. Επιπλέον, θεωρώ αναμενόμενο που το μοντέλο δεν είναι στο 100% της ακρίβειας, ίσως δεν είναι και εφικτό, διότι έχουμε περιορισμένο αριθμό χαρακτηριστικών που χρησιμοποιούνται για την πρόβλεψη.

# Δημιουργία των τριών ομάδων:
"""

age_test= X_test[:, -1]
group1= (age_test<=25)
group2=(age_test >25)& (age_test<=50)
group3=(age_test>50)

"""Υπολογισμός ακρίβειας κάθε ομάδας:"""

acc1= accuracy_score(y_test[group1], y_test_pred[group1])
acc2= accuracy_score(y_test[group2], y_test_pred[group2])
acc3 = accuracy_score(y_test[group3], y_test_pred[group3])

print("Accuracy 0-25:", acc1)
print("Accuracy 25-50:", acc2)
print("Accuracy >50:", acc3)

"""Ραβδόγραμμα για τις ομάδες των ηλικιών:"""

groups=['0-25', '25-50', '>50']
accurancies= [acc1, acc2, acc3]

plt.bar(groups, accurancies)
plt.title("Accurancy ανά ηλικιακή ομάδα στο test set")
plt.show()

"""Όπως ανέφερα και παραπάνω θεωρώ χειρότερο για τον ταξινομητή να προβλέπει ότι κάποιος ασθενής δεν έχει διαβήτη ενώ έχει. Κάτι τέτοιο κρύβει πολλούς κινδύνους για την υγεία των ασθενών.

## Για seeds από 0-9 με την ακρίβεια τους:
"""

accurancies=[]

for seed in range(10):
  X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=seed)
  model = LogisticRegression(random_state=0, max_iter=1000)
  model.fit(X_train, y_train)

  y_test_pred=model.predict(X_test)
  acc=accuracy_score(y_test, y_test_pred)
  accurancies.append(acc)

print(f"Accurancies:{accurancies}")

"""Μέσος όρος και τυπική απόκλιση:"""

mean_acc=np.mean(accurancies)
std_acc=np.std(accurancies)

print("Μέσος όρος ακρίβειας:",  mean_acc)
print("Τυπική απόκλιση:", std_acc)

"""Κανονικοποίηση Δεδομένων:"""

scaler=MinMaxScaler()
X_scaled=scaler.fit_transform(X)

"""Εκπαίδευση με τα κανονικοποιημένα δεδομένα:

"""

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=0)
model=LogisticRegression(random_state=0, max_iter=1000)
model.fit(X_train, y_train)

"""Συντελεστές:

# **Γραμμική Παλινδρόμηση:**
"""

X= df[['Pregnancies', 'BloodPressure', 'BMI', 'Age']].values
y=df['Glucose'].values

"""Διαχωρίζουμε πάλι τα δεδομένα σε train και test:"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

"""Εκπαίδευση Μοντέλου:"""

model=LinearRegression()
model.fit(X_train, y_train  )

"""Θα προβλέψουμε στο test set:"""

y_pred = model.predict(X_test)

"""Εύρεση καταλληλότερης μετρικής:"""

from sklearn.metrics import mean_squared_error, mean_absolute_error
mse= mean_squared_error(y_test, y_pred)
mae= mean_absolute_error(y_test, y_pred)

print("Mean squared error: ", mse)
print("Mean absolte error: ", mae)

"""Η καταλληλότερη μετρική με βάση το αποτέλεσμα είναι η Mean absolute error. Η άλλη μετρική επειδή τετραγωνίζει την διαφορά των τιμών μεγαλώνει πολύ τις ακραίες τιμές και τα λάθη. Ενώ η ΜΕΑ είναι πιο ρεαλιστική και πιο σταθερή για τις μεγάλες τιμές και στο συγκεκριμένο πρόβλημα που έχουμε μεγάλες τιμές γλυκόζης ταιριάζει περισσότερο.

Lasso Regression:
"""

from sklearn.linear_model import Lasso

results=[]
alpha=[0.2, 0.4, 0.6, 0.8, 1]

for a in alpha:
  model=Lasso(alpha=a)
  model.fit(X_train, y_train)
  y_pred=model.predict(X_test)
  mae=mean_absolute_error(y_test, y_pred)
  results.append([a,mae])

"""  Δημιουργία πίνακα αποτελεσμάτων:"""

results_df=pd.DataFrame(results, columns=['alpha', 'MAE'])
print(results_df)